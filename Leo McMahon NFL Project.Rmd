---
title: "NFL Running Back Project"
author: "Leo McMahon"
date: "2025-03-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}

```


```{r, include = FALSE}

library(readr)
library(glmnet)
library(sqldf)
library(dplyr)
library(tidyverse)
library(e1071)

combine <- read_csv("Downloads/archive/combine.csv")
draft <- read_csv("Downloads/archive/draft.csv")
fumbles <- read_csv("Downloads/archive/fumbles.csv")
gameParticipation <- read_csv("Downloads/archive/gameParticipation.csv")
games <- read_csv("Downloads/archive/games.csv")
players <- read_csv("Downloads/archive/players.csv")
plays <- read_csv("Downloads/archive/plays.csv")
rusher <- read_csv("Downloads/archive/rusher.csv")

```

# Introduction (First Down)

![](Downloads/jah.png)

With the NFL draft just around the corner (and the NFL combine just passed), now seems like the perfect time to analyze what makes a great NFL prospect. Specifically, for this project, I will be tackling what makes a great running back (RB), as they are often the engines of their offense. And while the quarterback is often given the most attention in the draft, if the 2024-2025 season showed us anything, it is that running backs can make a huge difference. 

The most important starting place here is to figure out what columns and relationships I actually want in my dataset, then I can do a SQL query to give me the dataset that I want. Here is an outline for the columns I want in my dataset:

IDENTIFICATION METRICS

1. playerid (primary key), an id that identifies the player.
2. nameFull, will just give me the full name of the player, this is for ease of use when I want the names as an output.
3. position, this will be RB for all of the players, but is jst nice for data cleanliness

COMBINE METRICS

4. height, height (in inches) at time of combine
5. weight, weight (in pounds) at time of combine
6. combine40yd, 40 yard dash time (in seconds) at combine
7. combineVert, vertical leap (in inches) at combine
8. combineBroad, broad jump length (in inches)
9. combine3cone, 3 cone time (in seconds) at combine

DRAFT METRICS

10. draftYear, year player was drafted
11. pick, # of pick that the player was drafted at
12. draftTradeValue, an approximate measure used to calculate the relative worth of picks in the NFL draft
13. draftTeam, team player was drafted to

NFL METRICS

15. rushYardsPerGame, returns total rushing yards divided by total games played in whole career.
16. yardsPerRushAttempt, returns total rushing yards over total rushing attempts.
17. rushTouchdownsPerGame, returns total touchdowns over total games played

EVALUATION METRICS

18. nflValue, a metric created by me that approximates a player's on-field value of their team as a function of rush yards per attempt, rush yard per game, and touchdowns per game. This measure also approximately follows the distribution of the draftTradeValue feature, meaning that we can compare the two to see if the player was worth their draft pick.
19. overperformance, this is a player's nflValue minus their draftTradeValue. So a high overperformance metric means that a player was worth much more than the draft pick at which they were taken
20. worthPick, a binary metric that simply states whether a player's overperformance is positive or negative (i.e. were they worth their pick or not)
21. steal, a binary metric that tells us if the player was a draft steal (i.e. their overperformance is above 300, meaning they became worth much more than the team paid for them.)

Now lets get to work on creating this dataframe. The NFL metrics are the only ones that have to be calculated, so I will first create a dataframe that gives me the information that I need.

This first data frame filters out for plays where the primary player used is a running back, so I can later take averages over all of these games.

```{r}

everyRushPlay <- sqldf(
  "select players.playerId, nameFull, season, plays.gameId, plays.playId, avg(rushYards) as rushYards, avg(rushTd) as rushTDs, fumbles.playerId > 0 as fumble
  from players inner join rusher on players.playerId = rusher.playerId inner join plays on rusher.playId = plays.playId inner join games on games.gameId = plays.gameId left join fumbles on fumbles.playid = plays.playId
  where position = 'RB'
  group by plays.playId"
)

```


In this data frame, I calculate the averages per play and per game for yards, and touchdowns per game as well (touchdowns per play would be miniscule and less important in my opinion)

```{r}
yardStats <- sqldf(
  "select playerId, nameFull, 
  sum(rushYards) / count(distinct gameId) as rushYardsPerGame, 
  sum(rushYards) / count(distinct playId) as yardsPerRushAttempt,
  sum(rushTDs) / count(distinct gameId) as rushTouchdownsPerGame
  from everyRushPlay
  group by playerId
  having count(distinct playId) > 20"
)

```

This final data frame is the full collection of every metric I will need for the rest of the project, and is especially important as it is where I calculate my tailored metrics.

```{r}

nfl <- sqldf(
  "select p.playerId, p.nameFull, p.position, 
  c.combineHeight, c.combineWeight, c.combine40yd, c.combineVert, c.combineBroad, c.combine3cone, 
  d.draft as draftYear, d.pick, d.draftTradeValue, d.draftTeam,
  y.rushYardsPerGame, y.yardsPerRushAttempt, y.rushTouchdownsPerGame, 
  0.01 * power(y.rushYardsPerGame, 2) * power(y.yardsPerRushAttempt, 3) * y.rushTouchdownsPerGame as nflValue,
  0.01 * power(y.rushYardsPerGame, 2) * power(y.yardsPerRushAttempt, 3) * y.rushTouchdownsPerGame - d.draftTradeValue as overperformance,
  CASE WHEN 0.01 * power(y.rushYardsPerGame, 2) * power(y.yardsPerRushAttempt, 3) * y.rushTouchdownsPerGame > d.draftTradeValue THEN 1 ELSE 0 END as worthPick,
  CASE WHEN 0.01 * power(y.rushYardsPerGame, 2) * power(y.yardsPerRushAttempt, 3) * y.rushTouchdownsPerGame - d.draftTradeValue > 300 THEN 1 ELSE 0 END as steal
  from yardStats y inner join players p on y.playerId = p.playerId inner join draft d on p.playerId = d.playerId inner join combine c on c.playerId = p.playerId
  "
)

```

Now that I have my data, it's time to find some patterns.

# Exploratory Data Analysis (Second Down)

![](Downloads/stiffarm.png)

I have constructed a measure of nfl success that attempts to estimate how good a player's nfl career is so that we have a semi-accurate way of measuring what makes a good player, and who coaches and teams should want to select in the draft. The central question of this project is as follows:

*Given limited information, how can we predict whether a player will be worth drafting at a certain pick?*

Throughout the course of this project, I will use classification models to try and determine whether or not a player is worth their draft pick, as well as some regression models that try to predicts a player's nfl value, and their relative value to their draft pick, so a team would be able to predict whether or not they are worth the draft pick they have.

To start, I will do a baseline linear regression model to see if we see any patterns emerging in predicting NFL value.

### Linear Regression Baseline

First, we split the data into train and test sets;

```{r}
set.seed(12)

train.mask = sample(nrow(nfl), 200)
nfl.train = na.omit(nfl[train.mask,])
nfl.test = na.omit(nfl[-train.mask,])


```

Now lets run a very basic linear regression on our training data and see if we can predict a player's NFL value based on their combine metrics.

```{r}

value_lm <- lm(nflValue~combineHeight + combineWeight + combine40yd + combineBroad + combineVert + combine3cone, nfl.train)

summary(value_lm)

```

This model reaches functionally no statistical significance, even having a near-zero adjusted R-squared value. Lets see if the two most statistically significant values (broad jump and 40 yard time) give us a better adjusted R-squared value.

```{r}

value_lm2 <- lm(nflValue~combineBroad + combine40yd, nfl.train)
summary(value_lm2)

```

Adjusted R-squared slightly increased, so lets further eliminate the 40 yard dash time.

```{r}

value_lm_broad <- lm(nflValue~combineBroad, nfl.train)
summary(value_lm_broad)

```

It may appear to show statistical significance, but in reality the adjusted R-squared is still low. Broad jump explains only ~8% of the variance in nflValue. However, in the NFL context, margins like 8% could be a significant difference. Contrary to the common belief that 40-yard dash times are the most important measure of a running back's potential, this data seems to suggest that broad jump may be a better predictor of success at the NFL level. In other words, scouts should focus on power over speed as a metric for success.

Now let's see what the test MSE is:

```{r}

predictions = predict(value_lm, newdata = na.omit(nfl.test))
MSE = mean((predictions-nfl.test$nflValue)^2)

predictions2 = predict(value_lm2, newdata = na.omit(nfl.test))
MSE2 = mean((predictions2-nfl.test$nflValue)^2)

predictions_broad = predict(value_lm_broad, newdata = na.omit(nfl.test))
MSE_broad = mean((predictions_broad-nfl.test$nflValue)^2)

MSE
MSE2
MSE_broad
```


Clearly none of these models are statistically significant. I will now try another basic method, logistic regression, to see if any of these metrics can predict whether a player will be worth their pick.

### Logistic Regression Baseline

First, I want to see what factors affect being worth a specific pick without knowing the actual pick the player was taken.

```{r}

logistic_no_pick = glm(worthPick~combineHeight + combineWeight + combine40yd + combineBroad + combineVert + combine3cone, data=nfl.train, family='binomial')

no_pick_predictions = predict(logistic_no_pick, newdata = nfl.test)

no_pick_test_error = 1-mean((no_pick_predictions>0.5) == nfl.test$worthPick)

no_pick_test_error

```

Not a good test error, so lets see if we can improve it. Now we will see what happens if we factor in what pick they were taken.

```{r}

logistic_w_pick = glm(worthPick~pick + combineHeight + combineWeight + combine40yd + combineBroad + combineVert + combine3cone, data=nfl.train, family='binomial')

w_pick_predictions = predict(logistic_w_pick, newdata = nfl.test)

w_pick_test_error = 1-mean((w_pick_predictions>0.5) == nfl.test$worthPick)

w_pick_test_error


```

Once pick is taken into account, we see our test error go down to only about 30%. If you could tell NFL scouts that you could predict whether or not a player would be worth a specific pick with ~70% accuracy, that would be a revelation. Let's see whats going into this model:

```{r}

summary(logistic_w_pick)

```

The only real statistically significant result is that that a higher numbered pick (i.e. later in the draft--remember pick 1 is the best pick) usually predicts they are more likely to overperform. This information may signal to NFL scouts that taking running backs very early in the draft (i.e. low numbered picks) is often not worth the risk, as they are less likely to live up to their perceived worth. Lets quickly perform some polynomial regression on a players pick vs his overperformance metric to find (historically) the ideal round/pick to get the best value for a running back.

# Visualization and Prediction (Third Down)

![](Downloads/saquon.png)

Now that we know the basics of how best to choose a player, lets see some more tailored graphs that will really help us make informed decisions on draft day.

### Polynomial Regression

First we will fit a polynomial graph (of degree 5 which seems to fit the data best) with pick on the x-axis vs overperformance on the y-axis to see when in the draft are we most likely to get our money's worth with a running back.

```{r}

nfl$round = as.factor(floor(nfl$pick/32) + 1)

ggplot(nfl, aes(pick, overperformance, color = round, 
                group = 1)) + geom_point() + stat_smooth(method=lm, formula = y~poly(x,5,raw=TRUE))


```

Polynomial regression is very sensitive at the edges of the data, so the uptick at the end can probably be ignored as it is caused by only a few outliers. Additionally, the NFL draft only has 7 rounds now, so no need to consider the 8th and 9th rounds in the data. The real important trend here that you are much more likely to get the best value for a running back if you take him in the late first round or the early second round. Obviously this is not to say that you should ever take running backs in later rounds. It is also not to say that if a generational prospect comes along, you should not take him early in the draft. What this graph tells us is that historically, if you have a top 5 pick, it is better off spent somewhere else, as running backs will less frequently return equal value to what the pick is worth. The smarter play would be to trade down to a lower pick, as the following historical example will tell us:

## Historical Example

Just two years ago, in the 2023 draft, the Detroit Lions (my favorite team) had the 6th overall pick in the draft, but they knew they wanted to draft running back Jahmyr Gibbs. They knew that drafting running backs are usually reserved for later first round picks, but they wanted to make sure that they got their guy. But when the Arizona Cardinals called them offering a trade, they wisely listened. The trade was as follows:

Detroit gains:

  12th overall pick, 34th overall pick
  
Arizona gains:

  6th overall pick
  
Figuring that no team would take the risk on Gibbs, the Lions accepted the trade. Gibbs was not drafted by any other team, and the Lions took him 12th overall, getting exactly who they wanted *and* getting an extra pick which turned into their current starting TE (tight end) Sam LaPorta. This was a genius trade that was supported by the knowledge that most teams would be waiting to take running backs until a bit later in the draft, so they could in essence gain a free pick and be sure that they were more likely to get good value out of Gibbs. Today, Gibbs is a consensus top five running back in the league (top 3 if you ask me) and has vastly outperformed even what the 6th overall pick would be worth. The Lions knew he was their guy, and they made informed decisions to get him for the best price.

### PCA for visualization

I will now perform some PCA to see if we can construct a graph that makes a meaningful split between players not worth their pick, players barely worth their pick, and players who were steals in the draft. We will only be using combine metrics, as any other metric has a direct correlation to a player being worth their pick (for example, if I were to include the players pick number, obviously certain groupings of picks will be easier to overperform with since they have a lower draftTradeValue)

```{r}

pca <- prcomp(na.omit(nfl)[,4:9], scale=TRUE, center=TRUE)

pca1 = pca$x[,1]
pca2 = pca$x[,2]

plot(pca1, pca2, col=ifelse(nfl$steal==1, "darkgreen",
                            ifelse(nfl$worthPick==1, "green", "red")))

```

There is clearly no meaningful separation here, so lets try plotting against the third principal component just in case it does a better job splitting the data.


```{r}

pca3 = pca$x[,3]

plot(pca1, pca3, col=ifelse(nfl$steal==1, "darkgreen",
                            ifelse(nfl$worthPick==1, "green", "red")))

```

Let's give it one last try with components 2 and 3

```{r}

plot(pca2, pca3, col=ifelse(nfl$steal==1, "darkgreen",
                            ifelse(nfl$worthPick==1, "green", "red")))

```

One minor pattern I am noticing (though minor) is that players who are considered "steals" appear to often have positive PC2 loadings. Not interpretable at all but if we were to have new player information and see that they have larger PC2 loadings, we might predict they are more likely to be a steal.

### Current Application

Ashton Jeanty, the star running back out of Boise State, will be drafted in the first round of this year's NFL draft. Some analysts have him going in the top 10 picks, even in the top 5 picks, but historically, we have seen that teams would be wise to wait. Even if it means that Jeanty ends up somewhere else, teams in the top 5 should avoid seling the farm for a running back, something we have shown to be detrimental to a team's long term success.

# Conclusion (Fourth Down)

![](Downloads/4th.png)

One of the most important insights from the regression portion of this project were that broad jump should be considered as an equally important, if not more important, combine measure than 40-yard dash time. Powerful running backs have historically been more successful in the NFL than fast running backs, so scouts should take note and be sure to watch for explosive broad jumps in the combine. But the most essential information is that even the best running backs are not worth taking in the top 10 picks. They underperform their value more often than not, and should only be considered in the top 20 if they are a truly special talent or the missing piece in a roster. 

At the end of the day, the most obvious outcome from the 4 statistical models (linear regression, logistic regression, polynomial regression, and PCA) was that scouts get it wrong about as often as they get it right. There is no surefire way to analyze a prospect, and there never will be. Thousands of unknown factors play into a player's success, and measuring them is simply impossible. The combine does its best to show us the physical ability of a player, but in reality it has nearly no predictive power over player success. So next time the NFL draft rolls around, and analysts are talking about 40-yard dash times or heavier vs. lighter running backs, just know that that is not the measure of a man in the NFL.


